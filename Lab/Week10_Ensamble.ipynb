{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week10_Ensamble.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2rjGzx7UmlJw"},"source":["# 앙상블"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n24CL9Gpy2ql","executionInfo":{"status":"ok","timestamp":1617320274933,"user_tz":-540,"elapsed":25790,"user":{"displayName":"김우혁","photoUrl":"","userId":"12967641707372735397"}},"outputId":"be86ef74-eb1d-4c24-83df-5de141a98190"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jK4CmAoMzbhY","executionInfo":{"status":"ok","timestamp":1617320405279,"user_tz":-540,"elapsed":627,"user":{"displayName":"김우혁","photoUrl":"","userId":"12967641707372735397"}}},"source":["import os\n","os.chdir('/content/drive/MyDrive/Universal_Bank')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h3qyjrY9zbdR"},"source":["### 과반수_투표"]},{"cell_type":"code","metadata":{"id":"Jsb1d_77uRYK","executionInfo":{"status":"ok","timestamp":1617320516861,"user_tz":-540,"elapsed":603,"user":{"displayName":"김우혁","photoUrl":"","userId":"12967641707372735397"}}},"source":["# 데이터 로더/ 학습에 사용할 특성변수 선택/ 데이터 분할\n","import pandas as pd\n","bank_df = pd.read_csv('UniversalBank.csv')\n","bank_df.head()\n","\n","X = bank_df.drop (['ID','ZIP Code','Personal Loan'], axis=1)\n","y = bank_df['Personal Loan']\n","\n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n","\n","# 앙상블에 사요할 3개의 모델 정의\n","from sklearn.tree import DecisionTreeClassifier # 결정 트리\n","from sklearn.neighbors import KNeighborsClassifier # K-최근접 이웃\n","from sklearn.linear_model import LogisticRegression # 로지스틱 회귀 모델\n","\n","logistic = LogisticRegression(solver='liblinear',\n","                              penalty='l2',\n","                              C=0.001,\n","                              random_state=1)\n","\n","tree = DecisionTreeClassifier(max_depth=None,\n","                              criterion='entropy',\n","                              random_state=1)\n","\n","knn = KNeighborsClassifier(n_neighbors=1,\n","                            p=2,\n","                            metric='minkowski')\n","\n","# 학습에 사용할 모델 앙상블 정의\n","from sklearn.ensemble import VotingClassifier # 과반수 투표(Majority Voting) \n","voting_estimators = [('logistic', logistic), ('tree', tree), ('knn', knn)]\n","voting = VotingClassifier(estimators = voting_estimators,\n","                          voting='soft')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNUDPZaSxa13","executionInfo":{"status":"ok","timestamp":1617320533188,"user_tz":-540,"elapsed":1216,"user":{"displayName":"김우혁","photoUrl":"","userId":"12967641707372735397"}},"outputId":"ebde2ca1-b9ba-4dfe-b815-d51a9916fed5"},"source":["## K-fold 교차 검증을 통한 모델 평가\n","\n","# 이전에는 Accuracy_score/Confusion_matrix 를 사용함\n","# cross_val_score의 scoring에 들어가는 스트링종류 : https://scikit-learn.org/stable/modules/model_evaluation.html 참고\n","from sklearn.model_selection import cross_val_score # 교차타당도 # 추가\n","\n","clf_labels = ['Logistic regression', 'Decision tree', 'KNN', 'Majority voting']\n","all_clf = [logistic, tree, knn, voting]\n","\n","for clf, label in zip(all_clf, clf_labels):\n","    scores = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=10,scoring='roc_auc') # cv(cross validation )=교차검증 횟수\n","    print(\"ROC AUC: %0.3f (+/- %0.3f) [%s]\", (scores.mean(), scores.std(), label))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["ROC AUC: %0.3f (+/- %0.3f) [%s] (0.9276195033668649, 0.01984630447185705, 'Logistic regression')\n","ROC AUC: %0.3f (+/- %0.3f) [%s] (0.9499227861055811, 0.032735680131811405, 'Decision tree')\n","ROC AUC: %0.3f (+/- %0.3f) [%s] (0.7120816883018249, 0.04722587272864442, 'KNN')\n","ROC AUC: %0.3f (+/- %0.3f) [%s] (0.9724206139059355, 0.01593603549077189, 'Majority voting')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P8TuA-9CzVre"},"source":["##### GridSearch 방식을 이용한 모델 최적화\n",": 모델의 하이퍼파라미터 튜닝에 사용"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cI27jx-Xx09F","executionInfo":{"status":"ok","timestamp":1617320547899,"user_tz":-540,"elapsed":12740,"user":{"displayName":"김우혁","photoUrl":"","userId":"12967641707372735397"}},"outputId":"36926bff-c72e-4365-9b3b-0026f68e74a7"},"source":["from sklearn.model_selection import GridSearchCV # 하이퍼파라미터 튜닝\n","\n","params = {'logistic__C': [0.001, 0.1, 100.0],\n","          'tree__max_depth': [1, 3, 5],\n","          'knn__n_neighbors': [1, 3, 5]}\n","# 3 x 3 x 3 = 27가지 조합\n","\n","grid = GridSearchCV(estimator=voting,\n","                    param_grid=params,\n","                    cv=10,\n","                    scoring='roc_auc',\n","                    iid=False)\n","grid.fit(X_train, y_train)\n","\n","for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n","    print(\"%0.3f +/- %0.3f %r\"\n","          % (grid.cv_results_['mean_test_score'][r], \n","             grid.cv_results_['std_test_score'][r] / 2.0, \n","             grid.cv_results_['params'][r]))\n","    \n","print('최적의 파타미터: %s' % grid.best_params_)\n","print('AUC: %.3f' % grid.best_score_)    "],"execution_count":14,"outputs":[{"output_type":"stream","text":["0.934 +/- 0.009 {'knn__n_neighbors': 1, 'logistic__C': 0.001, 'tree__max_depth': 1}\n","0.975 +/- 0.005 {'knn__n_neighbors': 1, 'logistic__C': 0.001, 'tree__max_depth': 3}\n","0.978 +/- 0.005 {'knn__n_neighbors': 1, 'logistic__C': 0.001, 'tree__max_depth': 5}\n","0.952 +/- 0.009 {'knn__n_neighbors': 1, 'logistic__C': 0.1, 'tree__max_depth': 1}\n","0.981 +/- 0.005 {'knn__n_neighbors': 1, 'logistic__C': 0.1, 'tree__max_depth': 3}\n","0.983 +/- 0.006 {'knn__n_neighbors': 1, 'logistic__C': 0.1, 'tree__max_depth': 5}\n","0.955 +/- 0.009 {'knn__n_neighbors': 1, 'logistic__C': 100.0, 'tree__max_depth': 1}\n","0.983 +/- 0.005 {'knn__n_neighbors': 1, 'logistic__C': 100.0, 'tree__max_depth': 3}\n","0.985 +/- 0.005 {'knn__n_neighbors': 1, 'logistic__C': 100.0, 'tree__max_depth': 5}\n","0.938 +/- 0.009 {'knn__n_neighbors': 3, 'logistic__C': 0.001, 'tree__max_depth': 1}\n","0.981 +/- 0.005 {'knn__n_neighbors': 3, 'logistic__C': 0.001, 'tree__max_depth': 3}\n","0.984 +/- 0.005 {'knn__n_neighbors': 3, 'logistic__C': 0.001, 'tree__max_depth': 5}\n","0.958 +/- 0.009 {'knn__n_neighbors': 3, 'logistic__C': 0.1, 'tree__max_depth': 1}\n","0.984 +/- 0.005 {'knn__n_neighbors': 3, 'logistic__C': 0.1, 'tree__max_depth': 3}\n","0.985 +/- 0.006 {'knn__n_neighbors': 3, 'logistic__C': 0.1, 'tree__max_depth': 5}\n","0.962 +/- 0.009 {'knn__n_neighbors': 3, 'logistic__C': 100.0, 'tree__max_depth': 1}\n","0.985 +/- 0.005 {'knn__n_neighbors': 3, 'logistic__C': 100.0, 'tree__max_depth': 3}\n","0.986 +/- 0.005 {'knn__n_neighbors': 3, 'logistic__C': 100.0, 'tree__max_depth': 5}\n","0.936 +/- 0.008 {'knn__n_neighbors': 5, 'logistic__C': 0.001, 'tree__max_depth': 1}\n","0.981 +/- 0.004 {'knn__n_neighbors': 5, 'logistic__C': 0.001, 'tree__max_depth': 3}\n","0.984 +/- 0.005 {'knn__n_neighbors': 5, 'logistic__C': 0.001, 'tree__max_depth': 5}\n","0.957 +/- 0.008 {'knn__n_neighbors': 5, 'logistic__C': 0.1, 'tree__max_depth': 1}\n","0.984 +/- 0.005 {'knn__n_neighbors': 5, 'logistic__C': 0.1, 'tree__max_depth': 3}\n","0.985 +/- 0.006 {'knn__n_neighbors': 5, 'logistic__C': 0.1, 'tree__max_depth': 5}\n","0.961 +/- 0.008 {'knn__n_neighbors': 5, 'logistic__C': 100.0, 'tree__max_depth': 1}\n","0.985 +/- 0.005 {'knn__n_neighbors': 5, 'logistic__C': 100.0, 'tree__max_depth': 3}\n","0.986 +/- 0.005 {'knn__n_neighbors': 5, 'logistic__C': 100.0, 'tree__max_depth': 5}\n","최적의 파타미터: {'knn__n_neighbors': 3, 'logistic__C': 100.0, 'tree__max_depth': 5}\n","AUC: 0.986\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n","  \"removed in 0.24.\", FutureWarning\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"CJERv9FloWHk"},"source":["###배깅"]},{"cell_type":"code","metadata":{"id":"lQgoaDsLob4A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617320871253,"user_tz":-540,"elapsed":22354,"user":{"displayName":"김우혁","photoUrl":"","userId":"12967641707372735397"}},"outputId":"9934c245-5f56-4793-862d-32afd55c2785"},"source":["# 데이터 로더/ 학습에 사용할 특성변수 선택/ 데이터 분할\n","import pandas as pd\n","bank_df = pd.read_csv('UniversalBank.csv')\n","bank_df.head()\n","\n","X = bank_df.drop (['ID','ZIP Code','Personal Loan'], axis=1)\n","y = bank_df['Personal Loan']\n","\n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n","\n","# 학습에 사용할 모델 개별 정의\n","from sklearn.tree import DecisionTreeClassifier # 결정 트리 # 배깅은 하나의 알고리즘 사용\n","tree = DecisionTreeClassifier(max_depth=None,\n","                              criterion='entropy',\n","                              random_state=1)\n","\n","# 학습에 사용할 모델 앙상블 정의\n","from sklearn.ensemble import BaggingClassifier # 배깅(Bagging) \n","bagging = BaggingClassifier(base_estimator=tree, # 수정\n","                            n_estimators=500, # 트리의 개수  \n","                            max_samples=1.0, \n","                            max_features=1.0, \n","                            bootstrap=True, # 입력데이터 샘플링의 중복 허용 \n","                            bootstrap_features=False, \n","                            n_jobs=1, \n","                            random_state=1)\n","\n","# K-fold 교차 검증을 통한 모델 평가\n","from sklearn.model_selection import cross_val_score # 교차타당도 # 추가\n","clf_labels = ['Decision tree', 'Bagging'] # 차이 비교\n","all_clf = [tree, bagging]\n","for clf, label in zip(all_clf, clf_labels):\n","    scores = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=10,scoring='roc_auc')\n","    print(\"ROC AUC: %0.3f (+/- %0.3f) [%s]\", (scores.mean(), scores.std(), label))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["ROC AUC: %0.3f (+/- %0.3f) [%s] (0.9499227861055811, 0.032735680131811405, 'Decision tree')\n","ROC AUC: %0.3f (+/- %0.3f) [%s] (0.9976668161065998, 0.001775473982951, 'Bagging')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dzcx7xSmnhzT"},"source":["###아다부스트"]},{"cell_type":"code","metadata":{"id":"V2eO4z4onqL4"},"source":["# 데이터 로더/ 학습에 사용할 특성변수 선택/ 데이터 분할\n","import pandas as pd\n","bank_df = pd.read_csv('UniversalBank.csv')\n","bank_df.head()\n","\n","X = bank_df.drop (['ID','ZI PCode','Personal Loan'], axis=1)\n","y = bank_df['Personal Loan']\n","\n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n","\n","# 학습에서 사용할 모델 개별 정의\n","from sklearn.tree import DecisionTreeClassifier # 결정 트리\n","tree = DecisionTreeClassifier(max_depth=1, # 배깅과 차이점: max_depth =1 로 변경\n","                              criterion='entropy',\n","                              random_state=1)\n","\n","# 학습에 사용할 모델 앙상블 정의\n","from sklearn.ensemble import AdaBoostClassifier # 부스팅(Boosting) \n","adaboost = AdaBoostClassifier(base_estimator=tree, # 수정\n","                              n_estimators=500,\n","                              learning_rate = 0.1, # 수정\n","                              random_state=1)\n","\n","## K-fold 교차 검증을 통한 모델 평가\n","from sklearn.model_selection import cross_val_score # 교차타당도 # 추가\n","clf_labels = ['Decision tree', 'Ada boost']\n","all_clf = [tree, adaboost]\n","for clf, label in zip(all_clf, clf_labels):\n","    scores = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=10,scoring='roc_auc')\n","    print(\"ROC AUC: %0.3f (+/- %0.3f) [%s]\", (scores.mean(), scores.std(), label))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GuioCGRFo6lV"},"source":["###파이프라인"]},{"cell_type":"code","metadata":{"id":"IN3IdHI0pi3L"},"source":["# 데이터 로더/ 학습에 사용할 특성변수 선택/ 데이터 분할\n","import pandas as pd\n","bank_df = pd.read_csv('UniversalBank.csv')\n","bank_df.head()\n","\n","X = bank_df.drop (['ID','ZIP Code','Personal Loan'], axis=1)\n","y = bank_df['Personal Loan']\n","\n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n","\n","# 학습에 사용할 모델 개별 정의\n","from sklearn.tree import DecisionTreeClassifier # 결정 트리\n","tree = DecisionTreeClassifier(max_depth=None, criterion='gini',random_state=1)\n","tree.fit(X_train, y_train)\n","\n","# 모델 검정\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score # 정확도, 민감도 등\n","y_pred = tree.predict(X_test)\n","print('잘못 분류된 샘플 개수: %d' % (y_test != y_pred).sum())\n","print('정확도: %.3f' % accuracy_score(y_test, y_pred))\n","print('정밀도: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n","print('재현율: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n","print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))\n","\n","# 교차검증\n","from sklearn.model_selection import cross_validate # 교차타당도\n","from sklearn.pipeline import make_pipeline # 파이프라인 구축\n","import numpy as np\n","scores = cross_validate(estimator=tree, \n","                        X=X_train, \n","                        y=y_train, \n","                        scoring=['accuracy'], \n","                        cv=10, \n","                        n_jobs=-1,\n","                        return_train_score=False)\n","print('CV 정확도 점수: %s' % scores['test_accuracy'])\n","print('CV 정확도: %.3f +/- %.3f' % (np.mean(scores['test_accuracy']), \n","                                 np.std(scores['test_accuracy'])))\n","\n","\n","## 파이프라인 학습\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import GridSearchCV\n","\n","#pipe_tree = make_pipeline( StandardScaler(), PCA(n_components=10), DecisionTreeClassifier())  # 98.514\n","pipe_tree = make_pipeline(DecisionTreeClassifier())\n","\n","param_range1 = [1,2,3,4,5,6,7,8,9,10] # 수정\n","param_range2 = [10,20,30,40,50] # 수정\n","\n","param_grid = [{'decisiontreeclassifier__max_depth': param_range1, # 수정\n","               'decisiontreeclassifier__min_samples_leaf': param_range2}] # 수정\n","\n","gs = GridSearchCV(estimator=pipe_tree, # 수정\n","                  param_grid=param_grid, \n","                  scoring='accuracy', \n","                  cv=10,\n","                  n_jobs=-1)\n","\n","gs = gs.fit(X_train, y_train)\n","\n","print(gs.best_score_)\n","print(gs.best_params_)\n","\n","# 파이파라인 학습 모델 검정\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","best_tree = gs.best_estimator_ # 최적의 파라미터가 적용된 모델\n","best_tree.fit(X_train, y_train) # 학습\n","y_pred = best_tree.predict(X_test) # 예측\n","\n","print('Classification Report')\n","print(classification_report(y_test, y_pred))"],"execution_count":null,"outputs":[]}]}